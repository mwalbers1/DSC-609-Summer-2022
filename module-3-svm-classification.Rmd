---
title: "Classification Machine Learning Models"
author: "Michael Albers"
date: '2022-07-21'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Libraries


```{r tidyverse library, echo=FALSE, warning=FALSE, message=FALSE}
library(tidyverse)
```

```{r utility libraries, echo=FALSE, warning=FALSE, message=FALSE}
library(janitor)
library(skimr)
library(lubridate)
```

```{r caret library, echo=FALSE, warning=FALSE, message=FALSE}
library(caret)
```

```{r rpart library, echo=FALSE, warning=FALSE, message=FALSE}
library(rpart)
```

```{r class library, echo=FALSE, warning=FALSE, message=FALSE}
library(class)
```


## Overview

- Run a kernelized SVM model on a bike sharing data set
- Implement two other classification models on same data set
- Compare and contrast results of each classification model


## Data Set

Lyft Bikes and Scooters, LLC (“Bikeshare”) operates the City of Chicago’s (“City”) Divvy bicycle sharing service (https://divvybikes.com). Bikeshare and the City are committed to supporting bicycling as an alternative transportation option. As part of that commitment, the City permits Bikeshare to make certain Divvy system data owned by the City (“Data”) available to the public. 

License Agreement: https://ride.divvybikes.com/data-license-agreement

Download link: https://divvy-tripdata.s3.amazonaws.com/index.html


## Read and Inspect data set

The bike sharing data file for the month of May in 2021 will be the data source.  The dependent variable for the classification models is the member_casual column.  The classification models will try and predict whether a bike customer is member or a casual bike rider.


```{r read in divvy data (dd)}
dd <- read.csv('data/202105-divvy-tripdata.csv')
```

```{r}
glimpse(dd)
```

### Filter on the busiest starting bike station

Since there are over 530,000 trips for the month of May 2021, the classification models will be limited to the busiest starting bike station for May of 2021

```{r}
starting_and_end_stations <- dd %>% 
  filter(start_station_name != "" & end_station_name != "")
```

```{r}
starting_and_end_stations %>% 
  group_by(start_station_id, start_station_name) %>% 
  summarize(number_trips = n()) %>% 
  arrange(desc(number_trips))
```

```{r}
streeter_station.df <- starting_and_end_stations %>% 
  filter(start_station_id == 13022)
```

```{r}
glimpse(streeter_station.df)
```



```{r}
streeter_station.df$rideable_type <- factor(streeter_station.df$rideable_type, levels = c("classic_bike", "docked_bike", "electric_bike"))
```


```{r}
streeter_station.df$started_at <- ymd_hms(streeter_station.df$started_at)
```


```{r}
streeter_station.df$ended_at <- ymd_hms(streeter_station.df$ended_at)
```


```{r}
streeter_station.df$member_casual <- factor(streeter_station.df$member_casual, levels = c("casual", "member"))
```


```{r}
glimpse(streeter_station.df)
```



```{r}
streeter_station.df %>% 
  tabyl(rideable_type, member_casual) %>% 
  adorn_totals("col")
```

The label column is member_casual which has two possible values (member or casual).


## Pre processing of data set

### One-hot encode the rideable_type column

```{r}
dummy <- dummyVars("~ rideable_type", data = streeter_station.df, levelsOnly = TRUE)
```

```{r}
dummy
```


```{r}
dummy.df <- data.frame(predict(dummy, newdata = streeter_station.df))
```

```{r}
bike_trips.df <- cbind(streeter_station.df, dummy.df)
```


### Create new features

  1. Week day number: Day of week that the person took a bike trip
  2. Start hour: The hour of the day that the person started on bike trip
  3. End hour: The hour of the day that the person ended his/her bike trip
  4. Trip duration: Duration of bike trip in minutes, calculated as ended_at minus started_at
  


```{r Day of week number}
bike_trips.df$weekday_num <- wday(bike_trips.df$started_at)
```


```{r Starting Hour of Bike trip}
bike_trips.df$start_hour <- as.numeric(format(as.POSIXct(bike_trips.df$started_at), format = "%H"))
```

```{r Ending Hour of Bike trip}
bike_trips.df$end_hour <- as.numeric(format(as.POSIXct(bike_trips.df$ended_at), format = "%H"))
```


```{r Bike trip duration}
bike_trips.df$trip_duration <- as.numeric(difftime(bike_trips.df$ended_at, bike_trips.df$started_at, units = "mins"))
```

```{r}
bike_trips.df <- subset(bike_trips.df,
			select = -c(start_station_id, start_station_name, start_lat, start_lng ))
```

```{r}
glimpse(bike_trips.df)
```

```{r}
summary(bike_trips.df)
```

## Visualization

Plot Electric Bikes for Casual and Member classes

```{r plot electric bikes}
electric_bikes.df <- bike_trips.df %>% 
  filter(electric_bike == 1) %>% 
  subset(select = c(end_lat, end_lng, weekday_num, trip_duration, start_hour, end_hour, member_casual))
```

```{r}
ggplot(data=electric_bikes.df, aes(x=end_lat, y=end_lng)) +
  geom_jitter() +
  geom_point(aes(color=member_casual)) +
  labs(title="Electric Bikes - Destination Coordinates")
```

```{r}
ggplot(data=electric_bikes.df, aes(x=weekday_num, y=trip_duration)) +
  geom_point(aes(color=member_casual)) +
  geom_jitter(aes(color=member_casual), width = 0.35) +
  labs(title="Electric Bikes - Trip Duration v. Weekday")
```

```{r}
ggplot(data=electric_bikes.df, aes(x=start_hour, y=end_hour)) +
  geom_point(aes(color=member_casual)) +
  facet_wrap(~member_casual) +
  geom_jitter(aes(color=member_casual), width = 2.5) +
  labs(title="Electric Bikes - Trip Starting v. Ending Hour")
```


## Set seed for reproduceability


```{r}
set.seed(42)
```


## Split Electric Bikes data into Training and Testing Sets

### Training data


```{r}
train_index <- sample(1:nrow(electric_bikes.df), 0.75 * nrow(electric_bikes.df))
```

```{r}
train_data <- electric_bikes.df[train_index, 1:6]
```

```{r}
glimpse(train_data)
```

```{r}
train_classes <- electric_bikes.df[train_index, 7]
```

```{r}
train_classes %>% 
  tabyl() %>% 
  adorn_totals(c("row","col"))
```


### Test data


```{r}
test_data <- electric_bikes.df[-train_index, 1:6]
```

```{r}
glimpse(test_data)
```

```{r}
test_classes <- electric_bikes.df[-train_index, 7]
```

```{r}
test_classes %>% 
  tabyl() %>% 
  adorn_totals(c("row","col"))
```



## Classification Models


### Kernelized SVM

```{r}
fold <- trainControl(method = "cv", number = 5)
```

```{r}
param_grid <- expand.grid(sigma = c(0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 0.9),
                              C = c(0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1.5))
```


```{r}
svm.rbf.cv <- train(x=train_data, 
                    y=train_classes,
                    method = "svmRadial",
                    trControl = fold,
                    preProcess = c("center", "scale"),
                    tuneGrid = param_grid,
                    tuneLength = 5
                    )
```

```{r}
print(svm.rbf.cv)
```

```{r}
plot(svm.rbf.cv)
```


#### Predict classes using SVM Kernelized model


```{r}
svm_pred <- predict(svm.rbf.cv, test_data)
```

```{r}
confusionMatrix(svm_pred, test_classes, dnn = c("Prediction", "Actual"))
```


### Decision Tree

Perform cross-validation on training data using CART decision trees

```{r}
param_grid.cart <- expand.grid(cp = c(0, 0.01, 0.02, 0.25, 0.3, 0.5, 0.75, 0.9))
```


```{r}
cart.cv <- train(x=train_data, 
                 y=train_classes,
                 method = "rpart",
                 trControl = fold,
                 tuneGrid = param_grid.cart,
                 tuneLength = 5)
```

```{r}
print(cart.cv)
```

```{r}
plot(cart.cv)
```


#### Predict classes using Decision Tree model

```{r}
dtree_pred <- predict(cart.cv, test_data)
```

```{r}
confusionMatrix(dtree_pred, test_classes, dnn = c("Prediction", "Actual"))
```



### k-NN (k-Nearest Neighbors)


```{r}
folds.knn <- createFolds(electric_bikes.df[,7], k=5)
```

```{r}
sapply(folds.knn, length)
```

```{r}

for (i in 1:5) {
  knn.f <- folds.knn[[i]]
  num_items.f <- length(knn.f)
  split <- round(num_items.f * .75)
  
  knn.train <- electric_bikes.df[knn.f[1:split], c("end_lat","end_lng","weekday_num","trip_duration","start_hour","end_hour")]
  knn.train.labels <- electric_bikes.df[knn.f[1:split], c("member_casual")]
  
  knn.test <- electric_bikes.df[knn.f[(split+1):num_items.f], 
                                c("end_lat","end_lng","weekday_num","trip_duration","start_hour","end_hour")]
  knn.test.labels <- electric_bikes.df[knn.f[(split+1):num_items.f], c("member_casual")]
  
  p <- knn(train = knn.train, test = knn.test, cl = knn.train.labels, k = 3)
  cat(paste("fold number: ", i, "accuracy: ", mean(p == knn.test.labels)), sep = "\n\n")
  
  print(table(knn.test.labels, p, dnn=c("Actual", "Predicted")))
  
}
```

The k-NN model cross validation achieved an accuracy of 86%.  However, it successfully predicted just one member out of a total of eleven members.




